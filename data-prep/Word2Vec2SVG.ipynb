{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec2SVGClean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "from google.colab import files\n",
        "from itertools import chain\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import json"
      ],
      "metadata": {
        "id": "7se_ZE4F9wTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using value of each part of vector as distance, equally spacing around a point\n",
        "# just complicated by presence of negative values, will probably bump everything up by minimum of whole dataset for now\n",
        "\n",
        "def get_coordinates_for_vector(vector, min):\n",
        "  points = []\n",
        "  \n",
        "  for c,v in enumerate(vector):\n",
        "    point_angle = 2 * math.pi * c / len(vector)\n",
        "    x = (v + min) * math.cos(point_angle)\n",
        "    y = (v + min) * math.sin(point_angle)\n",
        "    points.append([x, y])\n",
        "\n",
        "  return points"
      ],
      "metadata": {
        "id": "kjb1BDd4ev23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting positive version of lowest value in the model data, just flattening and getting the minimum with min, abs to make positive whether negative or positive\n",
        "# all values will be increase by this so there are no negatives and the shape won't have points crossing over\n",
        "\n",
        "def get_model_min(model):\n",
        "  return abs(min(chain.from_iterable(model.wv['{}'.format(i)] for i in list(model.wv.vocab))))"
      ],
      "metadata": {
        "id": "0xgOqt5gcbw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_coords_all_words(model, min):\n",
        "  all_word_coords = {}\n",
        "  vocab = list(model.wv.vocab)\n",
        "  for i in vocab:\n",
        "    all_word_coords[i] = get_coordinates_for_vector(model.wv['{}'.format(i)], min)\n",
        "  return all_word_coords"
      ],
      "metadata": {
        "id": "MRN_zAnl_vqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_json(filename, data):\n",
        "  with open(filename + '.json', 'w') as file_:\n",
        "    json.dump(data, file_, ensure_ascii=False)\n",
        "  time.sleep(200)\n",
        "  files.download(filename + \".json\")"
      ],
      "metadata": {
        "id": "XyOKa9dsog-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# at this point, will be about a quarter visible - the part that is both x and y positive, so need to pad\n",
        "# for sake of comparisons best to do minimum for whole dataset\n",
        "\n",
        "def make_svg_friendly(points, min_=None, viewbox=100):\n",
        "  if not min_:\n",
        "    min_x = min([i[0] for i in points])\n",
        "    min_y = min([i[1] for i in points])\n",
        "\n",
        "    padding = abs(min([min_x, min_y]) * 1.5)\n",
        "  else:\n",
        "    padding = abs(min_ * 1.5)\n",
        "  # may later use viewbox size to try and scale the points to fit/fill better\n",
        "\n",
        "  point_str = \"\"\n",
        "  for point in points:\n",
        "    point_str += \",\".join([str(point[0] +padding), str(point[1] + padding)]) + \" \"\n",
        "\n",
        "  return point_str.rstrip()"
      ],
      "metadata": {
        "id": "1sIFuFa-PuVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_svg_min(coordinates_all_words): # coordinates_all_words will be dict with nested list values, want the smallest value from all, and can disregard keys\n",
        "  all_x_coords = []\n",
        "  all_y_coords = []\n",
        "\n",
        "  for i in list(coordinates_all_words.values()):\n",
        "    all_x_coords.append([j[0] for j in i])\n",
        "    all_y_coords.append([j[1] for j in i])\n",
        "\n",
        "  all_x_coords = list(chain.from_iterable(all_x_coords))\n",
        "  all_y_coords = list(chain.from_iterable(all_y_coords))\n",
        "\n",
        "  svg_min = abs(min([min(all_y_coords), min(all_x_coords)]))\n",
        "  return svg_min\n"
      ],
      "metadata": {
        "id": "UFjX1ccXrj1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_all_svg_polygon_strings(all_coords, offset): # all coords should be dict with word key and coordinate value as made above\n",
        "  svg_dict = {}\n",
        "  for k,v in all_coords.items():\n",
        "    svg_dict[k] = make_svg_friendly(v, offset)\n",
        "  return svg_dict"
      ],
      "metadata": {
        "id": "fNRnU6nenVS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add path to model file to use below eg:\n",
        "model = Word2Vec.load(\"scpword2vec.model\")\n",
        "\n",
        "# can do a quick check on the model with word expected to be in there eg:\n",
        "# print(model.wv.most_similar('containment'))"
      ],
      "metadata": {
        "id": "dsEXy8aq_o9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates_all_words = generate_coords_all_words(model, get_model_min(model))"
      ],
      "metadata": {
        "id": "oZ3iVBGxDu0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polygon_str_dict = make_all_svg_polygon_strings(coordinates_all_words, get_svg_min(coordinates_all_words) )"
      ],
      "metadata": {
        "id": "35o1PJuI9AZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# give name for json file eg below, auto download set up to work if run in google colab\n",
        "save_json( \"scp_word_polygon_keyvals\", polygon_str_dict)"
      ],
      "metadata": {
        "id": "wwidQhSj9O3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}