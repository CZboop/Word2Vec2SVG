{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec2SVGCleanClassNormalising.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "from google.colab import files\n",
        "from itertools import chain\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import json"
      ],
      "metadata": {
        "id": "7se_ZE4F9wTD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec2SVG:\n",
        "  def __init__(self, path_to_model):\n",
        "    self.model = Word2Vec.load(path_to_model)\n",
        "    self.normalise_all()\n",
        "\n",
        "    # getting positive version of lowest value in the model data, just flattening and getting the minimum with min, abs to make positive whether negative or positive\n",
        "    # all values will be increased by this so there are no negatives and the shape won't have points crossing over\n",
        "    self.min = abs(min(chain.from_iterable(self.normalised_vectors.get(i) for i in list(self.model.wv.vocab))))\n",
        "\n",
        "  # overall normalising method, gets the min and max for each vector point\n",
        "  # then loops through each word vector and adjusts points based on this\n",
        "  def normalise_all(self):\n",
        "    self.normalise_range()\n",
        "\n",
        "    normalised_vectors = {}\n",
        "    vocab = list(self.model.wv.vocab)\n",
        "    for i in vocab:\n",
        "      normalised_vectors[i] = self.normalise_word(self.model.wv[f'{i}'])\n",
        "\n",
        "    self.normalised_vectors = normalised_vectors \n",
        "    return normalised_vectors\n",
        "\n",
        "  # getting min and max range for each vector point across the corpus for use in normalising each coord\n",
        "  def normalise_range(self):\n",
        "    min_max = []\n",
        "    # loop through and get min and max by index across vectors for each word\n",
        "    # range is len of each vector\n",
        "    vocab_list = list(self.model.wv.vocab)\n",
        "    vector_list = [self.model.wv[f'{word}'] for word in vocab_list]\n",
        "    for i in range(len(vector_list[0])):\n",
        "      min_max.append([min([vector[i] for vector in vector_list]), max([vector[i] for vector in vector_list])])\n",
        "    self.vector_ranges = min_max\n",
        "    return min_max\n",
        "\n",
        "  # applying normaliseation to the vector passed in based on self.vector_ranges previously worked out for each point across corpus\n",
        "  def normalise_word(self, word_vector):\n",
        "    normalised_vec = []\n",
        "    for c, v in enumerate(word_vector):\n",
        "      normalised_vec.append( (v - self.vector_ranges[c][0]) / (self.vector_ranges[c][1] - self.vector_ranges[c][0]) * 10 )\n",
        "    return normalised_vec\n",
        "    \n",
        "  # using value of each part of vector as distance, equally spacing around a point\n",
        "  # bumping up by dataset minimum to cancel out negatives in the vector\n",
        "  def get_coordinates_for_vector(self, vector):\n",
        "    points = []\n",
        "    \n",
        "    for c,v in enumerate(vector):\n",
        "      point_angle = 2 * math.pi * c / len(vector)\n",
        "      x = (v + self.min) * math.cos(point_angle)\n",
        "      y = (v + self.min) * math.sin(point_angle)\n",
        "      points.append([x, y])\n",
        "\n",
        "    return points\n",
        "  \n",
        "  # runs the get_coordinates_for_vector method for all words in model and returns a dict with key = word and value = coordinates list\n",
        "  def generate_coords_all_words(self):\n",
        "    all_word_coords = {}\n",
        "    vocab = list(self.model.wv.vocab)\n",
        "    for i in vocab:\n",
        "      all_word_coords[i] = self.get_coordinates_for_vector(self.normalised_vectors.get(i))\n",
        "\n",
        "    self.all_word_coords = all_word_coords\n",
        "    return all_word_coords\n",
        "\n",
        "  # auto save and download based on running in google colab\n",
        "  def save_json(self, filename, data):\n",
        "    with open(filename + '.json', 'w') as file_:\n",
        "      json.dump(data, file_, ensure_ascii=False)\n",
        "    time.sleep(200)\n",
        "    files.download(filename + \".json\")\n",
        "\n",
        "  # at this point, will be about a quarter visible - the part that is both x and y positive, so need to pad\n",
        "  # also turns into a string formatted to work as svg polygon points\n",
        "  def make_svg_friendly(self, points, min_=None):\n",
        "    if not min_:\n",
        "      min_x = min([i[0] for i in points])\n",
        "      min_y = min([i[1] for i in points])\n",
        "\n",
        "      padding = abs(min([min_x, min_y]) * 1.5)\n",
        "    else:\n",
        "      padding = abs(min_ * 1.5)\n",
        "\n",
        "    # other key part of method turns coordinates into a string that can go straight into svg polygon points property\n",
        "    point_str = \"\"\n",
        "    for point in points:\n",
        "      point_str += \",\".join([str(point[0] +padding), str(point[1] + padding)]) + \" \"\n",
        "\n",
        "    return point_str.rstrip()\n",
        "\n",
        "  def get_svg_min(self, coordinates_all_words): # coordinates_all_words will be dict with nested list values, want the smallest value from all, and can disregard keys\n",
        "    all_x_coords = []\n",
        "    all_y_coords = []\n",
        "\n",
        "    for i in list(coordinates_all_words.values()):\n",
        "      all_x_coords.append([j[0] for j in i])\n",
        "      all_y_coords.append([j[1] for j in i])\n",
        "\n",
        "    all_x_coords = list(chain.from_iterable(all_x_coords))\n",
        "    all_y_coords = list(chain.from_iterable(all_y_coords))\n",
        "\n",
        "    svg_min = abs(min([min(all_y_coords), min(all_x_coords)]))\n",
        "    return svg_min\n",
        "  \n",
        "  def make_all_svg_polygon_strings(self, all_coords, offset): # all coords should be dict with word key and coordinate value as made above\n",
        "    svg_dict = {}\n",
        "    for k,v in all_coords.items():\n",
        "      svg_dict[k] = self.make_svg_friendly(v, offset)\n",
        "    return svg_dict\n",
        "\n",
        "  # to get final result, just run this method\n",
        "  def make_and_save(self, filename):\n",
        "    self.generate_coords_all_words()\n",
        "    self.polygon_strings = self.make_all_svg_polygon_strings(self.all_word_coords, self.get_svg_min(self.all_word_coords) )\n",
        "    self.save_json(filename, self.polygon_strings)\n",
        "  "
      ],
      "metadata": {
        "id": "a0CzSBeFX5zV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # usage example:\n",
        "# create class instance passing in the trained model to use\n",
        "converter = Word2Vec2SVG(\"scpword2vec_shortervec.model\")\n",
        "# run this method passing in filename for the end json file\n",
        "# will automatically download if run  in google colab which will take a few minutes\n",
        "converter.make_and_save(\"normalised_polygon_data_simple\")"
      ],
      "metadata": {
        "id": "SyZEWi31bcvQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f3393efe-f706-4430-85bc-6b11a5e366a0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_455850ca-e2b6-452d-a958-cbcc8e13e1e4\", \"normalised_polygon_data_simple.json\", 16966104)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}